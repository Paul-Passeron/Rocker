//-----------------------------------------------------------------------------
//  ROCKER PARSER
//  MIT License
//  Copyright (c) 2024 Paul Passeron
//-----------------------------------------------------------------------------

include "RockerSRC/token.rkr"
include "RockerSRC/lexer.rkr"
include "RockerSRC/stdlib.rkr"
include "RockerSRC/ast.rkr"

rec parser => {
    Toks: token [],
    Prog: ast,
    Cursor: int,
    Includes: string [],
}

let new_parser(l: token []): parser => {
    let includes: string [] => [];
    let res: parser => {
        Toks => l,
        Prog => NULL,
        Cursor => 0,
        Includes => includes
    };
    return res;
}

let peek_type(p: parser): token_type => {
    let tok: token => peek_token(p);
    return tok::Type;
}

let peek_token(p: parser): token => {
    let toks: token[] => p::Toks;
    return get(toks, p::Cursor);
}

let consume_token(p: parser): token => {
    let res: token => peek_token(p);
    p::Cursor => p::Cursor + 1;
    return res;
}

let print_error_prefix(p: parser): void => {
    let tok: token => peek_token(p);
    print(tok::Filename);
    print(":");
    print_int(tok::Line);
    print(":");
    print_int(tok::Col);
}

let expect(p: parser, t: token_type): void => {
    let a: token_type => peek_type(p);
    if a != t then {
        print_error_prefix(p);
        print(" Expected ");
        print(lexeme_of_type(t));
        print(" but got: ");
        print(lexeme_of_type(a));
        print("\n");
        exit(1);
    }
}

let copy_parser(p: parser): parser => {
    let toks: token [] => p::Toks;
    let includes: string [] => p::Includes;
    let res: parser => {
        Toks => toks,
        Prog => p::Prog,
        Cursor => p::Cursor,
        Includes => includes,
    };
    return res;
}

let is_assign(p: parser): boolean => {
    let _p: parser => copy_parser(p);
    let scope: int => 0;
    let current: token_type => peek_type(_p);
    consume_token(_p);
    let break_cond: boolean => false;
    if current = TOK_OPEN_BRACE || current = TOK_CLOSE_BRACE then
        return false;
    while scope >= 0 && current != TOK_BIG_ARROW && break_cond = false do {
        if current = TOK_OPEN_BRACE || current = TOK_OPEN_BRACE then
            scope => scope + 1;
        else if current = TOK_CLOSE_BRACE || current = TOK_CLOSE_BRACE then
            scope => scope - 1;
        else if
            current = TOK_COMMA || current = TOK_SEMICOL ||
            current = TOK_COLON || current = TOK_LOOP ||
            current = TOK_SMALL_ARROW then break_cond => true;
        if break_cond = false then {
            current => peek_type(_p);
            consume_token(_p);
        }
    }
    return current = TOK_BIG_ARROW;
}



let parse_assign(p: parser): ast => {
    expect(p, TOK_IDENTIFIER);
    let target: ast => parse_expression(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    let expr: ast => parse_expression(p);
    expect(p, TOK_SEMICOL);
    consume_token(p);

    // A bit unconvenient but this will do
    let tag: ast_kind => tag_assign;
    let data_assign: ast_assign => {
        target => target,
        expr => expr,
    };
    let data: ast_data => {
        data_assign => data_assign,
    };
    let res: ast => {
        Tag => tag,
        Data => data,
    };
    return res;
}

let parse_cons(p: parser): ast => {
    expect(p, TOK_IDENTIFIER);
    let name: token => consume_token(p);
    expect(p, TOK_COLON);
    consume_token(p);
    let t: ast => parse_type(p);
    if peek_type(p) = TOK_COMMA then
        consume_token(p);
    
    let cons: ast_cons => {
        name => name,
        type => t,
    };
    let data: ast_data => {
        data_cons => cons
    };
    let res: ast => {
        Tag => tag_cons,
        Data => data 
    };
    return res;
}


let parse_tdef(p: parser): ast => {
    let type: tdef_type => 0;
    if peek_type(p) = TOK_REC then type => TDEF_REC;
    else if peek_type(p) = TOK_PRO then type => TDEF_PRO;
    else expect(p, TOK_REC);
    consume_token(p);
    expect(p, TOK_IDENTIFIER);
    let name: token => consume_token(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    expect(p, TOK_OPEN_BRACE);
    consume_token(p);
    let conss: ast [] => [];
    while peek_type(p) != TOK_CLOSE_BRACE do
        append(conss, parse_cons(p));
    consume_token(p);
    let data_tdef: ast_tdef => {
        name => name,
        t => type,
        constructors => conss
    };
    let data: ast_data => {
        data_tdef => data_tdef,
    };
    let res: ast => {
        Tag => tag_tdef,
        Data => data
    };
    return res;
}

let parse_ret(p: parser): ast => {
    expect(p, TOK_RETURN);
    consume_token(p);
    let data_ret: ast_ret => {
        expr => NULL,
    };
    if peek_type(p) != TOK_SEMICOL then
        data_ret::expr => parse_expression(p);
    expect(p, TOK_SEMICOL);
    consume_token(p);
    let data: ast_data => {
        data_ret => data_ret
    };
    let res: ast => {
        Tag => tag_ret,
        Data => data
    };
    return res;
}

let parse_literal(p: parser): ast => {
    let data_literal: ast_literal => {
        lit => consume_token(p),
    };
     let data: ast_data => {
        data_literal => data_literal
    };
    let res: ast => {
        Tag => tag_literal,
        Data => data
    };
    return res;
}

let parse_sub(p: parser): ast => {
    let path: token [] => [];
    append(path, consume_token(p));
    let exit_cond: boolean => false;
    while peek_type(p) = TOK_SUB && exit_cond = false do {
        consume_token(p);
        if(is_sub(p)) then append(path, consume_token(p));
        else exit_cond => true;
    }
    let expr: ast => parse_expression(p);
    let data_sub: ast_sub => {
        path => path,
        expr => expr,
    };
    let data: ast_data => {
        data_sub => data_sub,
    };
    let res: ast => {
        Tag => tag_sub,
        Data => data
    };
    return res;
}

let parse_if(p: parser): ast => {
    expect(p, TOK_IF);
    consume_token(p);
    let condition: ast => parse_expression(p);
    expect(p, TOK_THEN);
    consume_token(p);
    let body: ast => parse_statement(p);
    let data_ifstmt: ast_ifstmt => {
        expr => condition,
        body => body,
        elsestmt => NULL
    };
    if peek_type(p) = TOK_ELSE then {
        consume_token(p);
        data_ifstmt::elsestmt => parse_statement(p);
    }
    let data: ast_data => {
        data_ifstmt => data_ifstmt,
    };
    let res: ast => {
        Tag => tag_ifstmt,
        Data => data
    };
    return res;
}

let parse_enum(p: parser): ast => {
    expect(p, TOK_ENUM);
    consume_token(p);
    expect(p, TOK_IDENTIFIER);
    let name: token => consume_token(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    expect(p, TOK_OPEN_BRACE);
    consume_token(p);
    let elems: token [] => [];
    let break_cond: boolean => false;
    while peek_type(p) != TOK_CLOSE_BRACE && break_cond = false do {
        expect(p, TOK_IDENTIFIER);
        append(elems, consume_token(p));
        if peek_type(p) != TOK_COMMA then
            break_cond => true;
        else consume_token(p);
    }
    expect(p, TOK_CLOSE_BRACE);
    consume_token(p);
    let data_enum_tdef: ast_enum_tdef => {
        name => name,
        items => elems,
    };
    let data: ast_data => {
        data_enum_tdef => data_enum_tdef,
    };
    let res: ast => {
        Tag => tag_enum_tdef,
        Data => data
    };
    return res;
}

let parse_statement(p: parser): ast => {
    let a: token_type => peek_type(p);
    if a = TOK_IF then return parse_if(p);
    if a = TOK_ENUM then return parse_enum(p);
    if a = TOK_PRO || a = TOK_REC then return parse_tdef(p);
    if a = TOK_WHILE then return parse_while_loop(p);
    if is_assign(p) then return parse_assign(p);
    if a = TOK_LOOP then return parse_loop(p);
    if a = TOK_RETURN then return parse_ret(p);
    if a = TOK_MATCH then return parse_match(p);
    if a = TOK_OPEN_BRACE then return parse_compound(p);
    if a = TOK_LET then {
        let p2: parser => copy_parser(p);
        consume_token(p2);
        consume_token(p2);
        if peek_type(p2) = TOK_OPEN_PAREN then return parse_fundef(p);
        return parse_var_def(p);
    }
    let res: ast => parse_expression(p);
    expect(p, TOK_SEMICOL);
    consume_token(p);
    return res;
}   


let parse_matchcase(p: parser): ast => {
    implemented("parse_matchcase");
    return NULL;
}

let parse_match(p: parser): ast => {
    implemented("parse_match");
    return NULL;
}

let parse_compound(p: parser): ast => {
    expect(p, TOK_OPEN_BRACE);
    consume_token(p);
    let stmts: ast [] => [];
    while peek_type(p) != TOK_CLOSE_BRACE do 
        append(stmts, parse_statement(p));
    consume_token(p);
    let data_compound: ast_compound => {stmts => stmts};
    let data: ast_data => {
        data_compound => data_compound,
    };
    let res: ast => {
        Tag => tag_compound,
        Data => data
    };
    return res;
}

let parse_var_def(p: parser): ast => {
    expect(p, TOK_LET);
    consume_token(p);
    let id: token => consume_token(p);
    expect(p, TOK_COLON);
    consume_token(p);
    let type: ast => parse_type(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    let data_vardef: ast_vardef => {
        name => id,
        is_rec => false,
        expr => NULL,
        type => type,
    };
    if peek_type(p) = TOK_OPEN_BRACE then {
        data_vardef::is_rec => true;
        consume_token(p);
        data_vardef::expr => parse_record_expression(p);
    }
    else if peek_type(p) = TOK_ARR_DECL then 
        data_vardef::expr => parse_literal(p);
    else data_vardef::expr => parse_expression(p);
    expect(p, TOK_SEMICOL);
    consume_token(p);
    let data: ast_data => {
        data_vardef => data_vardef,
    };
    let res: ast => {
        Tag => tag_vardef,
        Data => data
    };
    return res;
    
}

let parse_fundef(p: parser): ast => {
    expect(p, TOK_LET);
    consume_token(p);
    let id: token => consume_token(p);
    expect(p, TOK_OPEN_PAREN);
    consume_token(p);
    let args: token [] => [];
    let types: ast [] => [];
    let break_cond: boolean => false;
    while peek_type(p) != TOK_CLOSE_PAREN && break_cond = false do {
        expect(p, TOK_IDENTIFIER);
        append(args, consume_token(p));
        expect(p, TOK_COLON);
        consume_token(p);
        append(types, parse_type(p));
        if peek_type(p) != TOK_COMMA then break_cond => true;
        else consume_token(p);
    }
    expect(p, TOK_CLOSE_PAREN);
    consume_token(p);
    expect(p, TOK_COLON);
    consume_token(p);
    let type: ast => parse_type(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    let body: ast => parse_compound(p);
    let data_fundef: ast_fundef => {
        name => id,
        args => args,
        types => types,
        body => body,
        ret_type => type
    };
    let data: ast_data => {
        data_fundef => data_fundef,
    };
    let res: ast => {
        Tag => tag_fundef,
        Data => data
    };
    return res;
}

let parse_loop(p: parser): ast => {
    expect(p, TOK_LOOP);
    consume_token(p);
    expect(p, TOK_IDENTIFIER);
    let var_name: token => consume_token(p);
    expect(p, TOK_COLON);
    consume_token(p);
    let begin: ast => parse_expression(p);
    expect(p, TOK_SMALL_ARROW);
    consume_token(p);
    let end: ast => parse_expression(p);
    expect(p, TOK_BIG_ARROW);
    consume_token(p);
    let body: ast => parse_statement(p);
    let data_loop: ast_loop => {
       variable => var_name,
       start => begin,
       end => end,
       statement => body,
    };
    let data: ast_data => {
        data_loop => data_loop,
    };
    let res: ast => {
        Tag => tag_loop,
        Data => data
    };
    return res;

}

let is_primary(p: parser): boolean => {
    let t: token_type => peek_type(p);
    return t = TOK_OPEN_BRACE || t = TOK_OPEN_PAREN
        || t = TOK_IDENTIFIER || t = TOK_STR_LIT
        || t = TOK_CHR_LIT    || t = TOK_NUM_LIT 
        || t = TOK_WILDCARD   || t = TOK_ARR_DECL;
}

let is_funcall(p: parser): boolean => {
    let p2: parser => copy_parser(p);
    if peek_type(p2) != TOK_IDENTIFIER then return false;
    consume_token(p2); 
    if peek_type(p2) != TOK_OPEN_PAREN then return false;
    return true;
}

let parse_funcall(p: parser): ast => {
    let id: token => consume_token(p);
    expect(p, TOK_OPEN_PAREN);
    consume_token(p);
    let args: ast [] => [];
    let break_cond: boolean => false;
    while peek_type(p) != TOK_CLOSE_PAREN && break_cond = false do {
        append(args, parse_expression(p));
        if peek_type(p) != TOK_COMMA then break_cond => true;
        else consume_token(p);
    }
    expect(p, TOK_CLOSE_PAREN);
    consume_token(p);
    let data_funcall: ast_funcall => {
        name => id,
        args => args,
    };
    let data: ast_data => {
        data_funcall => data_funcall,
    };
    let res: ast => {
        Tag => tag_funcall,
        Data => data
    };
    return res;
}

let parse_while_loop(p: parser): ast => {
    expect(p, TOK_WHILE);
    consume_token(p);
    let condition: ast => parse_expression(p);
    expect(p, TOK_DO);
    consume_token(p);
    let statement: ast => parse_statement(p);
    let data_while_loop: ast_while_loop => {
       condition => condition,
       statement => statement,
    };
    let data: ast_data => {
        data_while_loop => data_while_loop,
    };
    let res: ast => {
        Tag => tag_while_loop,
        Data => data
    };
    return res;
}

let parse_record_expression(p: parser): ast => {
    let names: token [] => [];
    let exprs: ast [] => [];
    let break_cond: boolean => false;
    while peek_type(p) != TOK_CLOSE_BRACE && break_cond = false do {
        expect(p, TOK_IDENTIFIER);
        let cons_name: token => consume_token(p);
        append(names, cons_name);
        expect(p, TOK_BIG_ARROW);
        consume_token(p);
        let expr: ast => parse_expression(p);
        append(exprs, expr);
        if peek_type(p) != TOK_COMMA then break_cond => true;
        else consume_token(p);
    }
    expect(p, TOK_CLOSE_BRACE);
    consume_token(p);
    let data_record_expr: ast_record_expr => {
       exprs => exprs,
       names => names
    };
    let data: ast_data => {
        data_record_expr => data_record_expr,
    };
    let res: ast => {
        Tag => tag_record_expr,
        Data => data
    };
    return res;
}


let parse_type(p: parser): ast => {
   expect(p, TOK_IDENTIFIER);
   let name: token => consume_token(p);
   let is_arr: boolean => false;
   if peek_type(p) = TOK_ARR_DECL then {
    consume_token(p);
    is_arr => true;
   }
   let data_type: ast_type => {
      name => name,
      is_array => is_arr,
    };
    let data: ast_data => {
        data_type => data_type,
    };
    let res: ast => {
        Tag => tag_type,
        Data => data
    };
    return res;
}

let parse_identifier(p: parser): ast => {
    let t: token => consume_token(p);
    let data_identifier: ast_identifier => {id => t};
    let data: ast_data => {
        data_identifier => data_identifier,
    };
    let res: ast => {
        Tag => tag_identifier,
        Data => data
    };
    return res;
}

let parse_leaf(p: parser): ast => {
    if is_funcall(p) then return parse_funcall(p);
    let t: token_type => peek_type(p);
    if t = TOK_IDENTIFIER then return parse_identifier(p);
    return parse_literal(p);
}

let is_sub(p: parser): boolean => {
    let p2: parser => copy_parser(p);
    if peek_type(p2) != TOK_IDENTIFIER then return false;
    consume_token(p2);
    if peek_type(p2) != TOK_SUB then return false;
    return true;
}

let is_leaf(p: parser): boolean => {
    let type: token_type => peek_type(p);
    return type = TOK_STR_LIT || type = TOK_CHR_LIT  ||
       type = TOK_NUM_LIT     || type = TOK_WILDCARD ||
       type = TOK_IDENTIFIER  || type = TOK_ARR_DECL;  
}

let parse_primary(p: parser): ast => {
    if is_funcall(p) then return parse_funcall(p);
    if is_sub(p) then return parse_sub(p);
    if is_leaf(p) then return parse_leaf(p);
    if peek_type(p) = TOK_OPEN_PAREN then {
        consume_token(p);
        let res: ast => parse_expression(p);
        // I dunno why I didn't use expect here
        if peek_type(p) != TOK_CLOSE_PAREN then {
            print_error_prefix(p);
            print("TODO: Unclosed parenthesis\n");
            exit(1);
        }
        consume_token(p);
        return res;
    }
    if peek_type(p) = TOK_OPEN_BRACE then
        return parse_record_expression(p);
    print_error_prefix(p);
    print(" TODO: Could not parse as primary \'");
    print(lexeme_of_type(peek_type(p)));
    print("\'\n");
    exit(1);
    return NULL; // For TCC
}

let parse_expression(p: parser): ast => {
    let a: token_type => peek_type(p);
    if a = TOK_OPEN_PAREN then {
        consume_token(p);
        let res: ast => parse_expression(p);
        expect(p, TOK_CLOSE_PAREN);
        consume_token(p);
        return res;
    }
    if a = TOK_OPEN_BRACE then {
        consume_token(p);
        return parse_record_expression(p);
    }
    return parse_expression_aux(p, 0);
}

let parse_expression_aux(p: parser, min_prec: int): ast => {
    let left: ast => parse_primary(p);
    let break_cond: boolean => false;
    while break_cond = false do {
        let node: ast => parse_increasing_precedence(p, left, min_prec);
        if node = left then
            break_cond => true;
        else left => node;
    }
    return left;
}

let parse_increasing_precedence(p: parser, left: ast, min_prec: int): ast => {
    let next: token_type => peek_type(p);
    if is_type_operator(next) = false then return left;
    let next_prec: int => get_precedence(next);
    if next_prec < min_prec then return left;
    consume_token(p);
    let right: ast => parse_expression_aux(p, next_prec);
    let data_op: ast_op => {
        op => next,
        left => left,
        right => right
    };
    let data: ast_data => {
        data_op => data_op
    };
    let res: ast => {
        Tag => tag_op,
        Data => data
    };
    return res;
}

let has_been_included(p: parser, filename: string): boolean => {
    let includes: string [] => p::Includes;
    let len: int => get_length(includes);
    loop i: 0 -> len - 1 =>
        if str_eq(filename, get(includes, i)) then return true; 
    return false;
}

let parse_program(p: parser): void => {
    let prog: ast [] => [];
    let tokens: token [] => p::Toks;
    let includes: string [] => p::Includes;
    // TODO: add the main file absolute path in includes
    while p::Cursor < get_length(tokens) do {
        tokens => p::Toks;
        if peek_type(p) = TOK_INCLUDE then {
            consume_token(p);
            expect(p, TOK_STR_LIT);
            let fn: token => consume_token(p);
            let filename: string => create_string(fn::Lexeme, 1, get_string_length(fn::Lexeme) - 2);
            let l: int => get_string_length(filename);
            let abs_path: string => get_abs_path(filename);
            if has_been_included(p, abs_path) = false then {
                append(includes, abs_path);
                let l: lexer => new_lexer(filename);
                lex_program(l);
                let toks: token [] => l::Toks;
                let new_toks: token [] => [];
                loop i: 0 -> p::Cursor - 1 => 
                    append(new_toks, get(tokens, i));
                loop i: 0 -> get_length(toks) - 1 => 
                    append(new_toks, get(toks, i));
                loop i: p::Cursor -> get_length(tokens) -1 => 
                    append(new_toks, get(tokens, i));
                p::Toks => new_toks;
            }
        }
        else
            append(prog, parse_statement(p));
    }
    let data_program: ast_program => { prog => prog };
    let data: ast_data => { data_program => data_program };
    let res: ast => {
        Tag => tag_program,
        Data => data
    };
    p::Prog => res;
}